{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae743fd4",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) for CS10 Satellite Image Classification\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis to inform CNN model design and training strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d134dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e007ab",
   "metadata": {},
   "source": [
    "## 1. DATASET OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fde7388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\Users\\Hyper\\Documents\\Personal\\Hackathons\\2025_HacX_Hackathon\\frontend\\HacX\n",
      "Train Directory: c:\\Users\\Hyper\\Documents\\Personal\\Hackathons\\2025_HacX_Hackathon\\frontend\\HacX\\train\n",
      "Test Directory: c:\\Users\\Hyper\\Documents\\Personal\\Hackathons\\2025_HacX_Hackathon\\frontend\\HacX\\test\n"
     ]
    }
   ],
   "source": [
    "# Configure dataset paths\n",
    "BASE_DIR = Path(r\"c:\\Users\\Hyper\\Documents\\Personal\\Hackathons\\2025_HacX_Hackathon\\frontend\\HacX\")\n",
    "TRAIN_DIR = BASE_DIR / \"train\"\n",
    "TEST_DIR = BASE_DIR / \"test\"\n",
    "\n",
    "CLASSES = ['normal', 'haze', 'smoke']\n",
    "CLASS_COLORS = {'normal': '#2ecc71', 'haze': '#f39c12', 'smoke': '#e74c3c'}\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Train Directory: {TRAIN_DIR}\")\n",
    "print(f\"Test Directory: {TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63e6c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      " Class  Train Samples  Test Samples  Total  Train %\n",
      "normal           5048          1682   6730    67.60\n",
      "  haze           1202           400   1602    16.10\n",
      " smoke           1218           406   1624    16.31\n",
      "============================================================\n",
      "Total Training Samples: 7468\n",
      "Total Test Samples: 2488\n",
      "Total Samples: 9956\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_info(data_dir, classes):\n",
    "    \"\"\"\n",
    "    Load image file paths and count samples per class.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the dataset directory\n",
    "        classes: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with class names as keys and lists of image paths as values\n",
    "    \"\"\"\n",
    "    dataset_info = {cls: [] for cls in classes}\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_dir = data_dir / cls\n",
    "        if class_dir.exists():\n",
    "            # Get all image files (common extensions)\n",
    "            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif']\n",
    "            for ext in image_extensions:\n",
    "                dataset_info[cls].extend(list(class_dir.glob(f'*{ext}')))\n",
    "                dataset_info[cls].extend(list(class_dir.glob(f'*{ext.upper()}')))\n",
    "    \n",
    "    return dataset_info\n",
    "\n",
    "# Load training and test datasets\n",
    "train_data = load_dataset_info(TRAIN_DIR, CLASSES)\n",
    "test_data = load_dataset_info(TEST_DIR, CLASSES)\n",
    "\n",
    "# Count samples per class\n",
    "train_counts = {cls: len(paths) for cls, paths in train_data.items()}\n",
    "test_counts = {cls: len(paths) for cls, paths in test_data.items()}\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_summary = pd.DataFrame({\n",
    "    'Class': CLASSES,\n",
    "    'Train Samples': [train_counts[cls] for cls in CLASSES],\n",
    "    'Test Samples': [test_counts[cls] for cls in CLASSES],\n",
    "})\n",
    "df_summary['Total'] = df_summary['Train Samples'] + df_summary['Test Samples']\n",
    "df_summary['Train %'] = (df_summary['Train Samples'] / df_summary['Train Samples'].sum() * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Training Samples: {df_summary['Train Samples'].sum()}\")\n",
    "print(f\"Total Test Samples: {df_summary['Test Samples'].sum()}\")\n",
    "print(f\"Total Samples: {df_summary['Total'].sum()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54aa27b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Training set distribution\n",
    "axes[0].bar(CLASSES, [train_counts[cls] for cls in CLASSES], \n",
    "           color=[CLASS_COLORS[cls] for cls in CLASSES], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, cls in enumerate(CLASSES):\n",
    "    axes[0].text(i, train_counts[cls] + max(train_counts.values())*0.02, \n",
    "                str(train_counts[cls]), ha='center', fontweight='bold')\n",
    "\n",
    "# Test set distribution\n",
    "axes[1].bar(CLASSES, [test_counts[cls] for cls in CLASSES], \n",
    "           color=[CLASS_COLORS[cls] for cls in CLASSES], alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Test Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, cls in enumerate(CLASSES):\n",
    "    axes[1].text(i, test_counts[cls] + max(test_counts.values())*0.02, \n",
    "                str(test_counts[cls]), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c93bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASS BALANCE ANALYSIS\n",
      "============================================================\n",
      "normal    : 67.60% (5048 samples)\n",
      "haze      : 16.10% (1202 samples)\n",
      "smoke     : 16.31% (1218 samples)\n",
      "\n",
      "Imbalance Ratio: 4.20:1\n",
      "\n",
      "⚠️  MODERATE TO SEVERE CLASS IMBALANCE DETECTED\n",
      "\n",
      "🔧 RECOMMENDED STRATEGIES:\n",
      "   1. Class Weights: Assign higher weights to minority classes\n",
      "      - Use sklearn.utils.class_weight.compute_class_weight\n",
      "      - Apply in loss function (weighted cross-entropy)\n",
      "   2. Focal Loss: Focus training on hard examples\n",
      "      - Better than standard cross-entropy for imbalanced data\n",
      "   3. Augmentation: Apply more aggressive augmentation to minority classes\n",
      "   4. SMOTE/Oversampling: Synthetically oversample minority classes\n",
      "   5. Stratified Sampling: Ensure balanced batches during training\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "def analyze_class_balance(counts, threshold=0.15):\n",
    "    \"\"\"\n",
    "    Analyze class imbalance and recommend strategies.\n",
    "    \n",
    "    Args:\n",
    "        counts: Dictionary of class counts\n",
    "        threshold: Imbalance threshold (default 15%)\n",
    "    \"\"\"\n",
    "    total = sum(counts.values())\n",
    "    proportions = {cls: count/total for cls, count in counts.items()}\n",
    "    \n",
    "    max_prop = max(proportions.values())\n",
    "    min_prop = min(proportions.values())\n",
    "    imbalance_ratio = max_prop / min_prop\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLASS BALANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for cls, prop in proportions.items():\n",
    "        print(f\"{cls:10s}: {prop*100:5.2f}% ({counts[cls]:4d} samples)\")\n",
    "    \n",
    "    print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    \n",
    "    if imbalance_ratio > 1.5:\n",
    "        print(\"\\n⚠️  MODERATE TO SEVERE CLASS IMBALANCE DETECTED\")\n",
    "        print(\"\\n🔧 RECOMMENDED STRATEGIES:\")\n",
    "        print(\"   1. Class Weights: Assign higher weights to minority classes\")\n",
    "        print(\"      - Use sklearn.utils.class_weight.compute_class_weight\")\n",
    "        print(\"      - Apply in loss function (weighted cross-entropy)\")\n",
    "        print(\"   2. Focal Loss: Focus training on hard examples\")\n",
    "        print(\"      - Better than standard cross-entropy for imbalanced data\")\n",
    "        print(\"   3. Augmentation: Apply more aggressive augmentation to minority classes\")\n",
    "        print(\"   4. SMOTE/Oversampling: Synthetically oversample minority classes\")\n",
    "        print(\"   5. Stratified Sampling: Ensure balanced batches during training\")\n",
    "    elif imbalance_ratio > 1.2:\n",
    "        print(\"\\n⚠️  MILD CLASS IMBALANCE DETECTED\")\n",
    "        print(\"\\n🔧 RECOMMENDED STRATEGIES:\")\n",
    "        print(\"   1. Class Weights: Apply moderate weighting\")\n",
    "        print(\"   2. Stratified Sampling: Use stratified batches\")\n",
    "    else:\n",
    "        print(\"\\n✓ CLASSES ARE WELL BALANCED\")\n",
    "        print(\"   - Standard cross-entropy loss should work well\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return proportions, imbalance_ratio\n",
    "\n",
    "# Analyze training set balance\n",
    "train_props, train_imbalance = analyze_class_balance(train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790eaeee",
   "metadata": {},
   "source": [
    "## 2. IMAGE CHARACTERISTICS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(data_dict, sample_size=None):\n",
    "    \"\"\"\n",
    "    Analyze image dimensions, aspect ratios, and color channels.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        sample_size: Number of images to sample per class (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with image properties\n",
    "    \"\"\"\n",
    "    properties = []\n",
    "    \n",
    "    for cls, img_paths in data_dict.items():\n",
    "        paths_to_analyze = img_paths if sample_size is None else random.sample(img_paths, min(sample_size, len(img_paths)))\n",
    "        \n",
    "        for img_path in paths_to_analyze:\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                width, height = img.size\n",
    "                channels = len(img.getbands())\n",
    "                mode = img.mode\n",
    "                \n",
    "                properties.append({\n",
    "                    'class': cls,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'channels': channels,\n",
    "                    'mode': mode,\n",
    "                    'aspect_ratio': width / height,\n",
    "                    'total_pixels': width * height\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(properties)\n",
    "\n",
    "# Analyze training images (sample for speed if dataset is large)\n",
    "print(\"Analyzing image properties...\")\n",
    "df_props = analyze_image_properties(train_data, sample_size=100)  # Sample 100 per class for speed\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMAGE PROPERTIES SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n📊 DIMENSIONS:\")\n",
    "print(f\"   Width  - Min: {df_props['width'].min()}, Max: {df_props['width'].max()}, Mean: {df_props['width'].mean():.1f}\")\n",
    "print(f\"   Height - Min: {df_props['height'].min()}, Max: {df_props['height'].max()}, Mean: {df_props['height'].mean():.1f}\")\n",
    "\n",
    "print(\"\\n📊 ASPECT RATIOS:\")\n",
    "print(f\"   Min: {df_props['aspect_ratio'].min():.3f}\")\n",
    "print(f\"   Max: {df_props['aspect_ratio'].max():.3f}\")\n",
    "print(f\"   Mean: {df_props['aspect_ratio'].mean():.3f}\")\n",
    "\n",
    "print(\"\\n📊 COLOR MODES:\")\n",
    "print(df_props['mode'].value_counts().to_string())\n",
    "\n",
    "print(\"\\n📊 CHANNELS:\")\n",
    "print(df_props['channels'].value_counts().to_string())\n",
    "\n",
    "# Per-class statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PER-CLASS STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_props[df_props['class'] == cls]\n",
    "    print(f\"\\n{cls.upper()}:\")\n",
    "    print(f\"   Samples analyzed: {len(cls_data)}\")\n",
    "    print(f\"   Width:  {cls_data['width'].mean():.1f} ± {cls_data['width'].std():.1f}\")\n",
    "    print(f\"   Height: {cls_data['height'].mean():.1f} ± {cls_data['height'].std():.1f}\")\n",
    "    print(f\"   Aspect Ratio: {cls_data['aspect_ratio'].mean():.3f} ± {cls_data['aspect_ratio'].std():.3f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bff3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dimension distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Width distribution\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_props[df_props['class'] == cls]\n",
    "    axes[0, 0].hist(cls_data['width'], bins=30, alpha=0.5, label=cls, color=CLASS_COLORS[cls])\n",
    "axes[0, 0].set_title('Width Distribution by Class', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Width (pixels)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Height distribution\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_props[df_props['class'] == cls]\n",
    "    axes[0, 1].hist(cls_data['height'], bins=30, alpha=0.5, label=cls, color=CLASS_COLORS[cls])\n",
    "axes[0, 1].set_title('Height Distribution by Class', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Height (pixels)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Aspect ratio distribution\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_props[df_props['class'] == cls]\n",
    "    axes[1, 0].hist(cls_data['aspect_ratio'], bins=30, alpha=0.5, label=cls, color=CLASS_COLORS[cls])\n",
    "axes[1, 0].set_title('Aspect Ratio Distribution by Class', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Aspect Ratio (width/height)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Total pixels distribution\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_props[df_props['class'] == cls]\n",
    "    axes[1, 1].hist(cls_data['total_pixels']/1e6, bins=30, alpha=0.5, label=cls, color=CLASS_COLORS[cls])\n",
    "axes[1, 1].set_title('Image Size Distribution by Class', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Total Pixels (Megapixels)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for inconsistencies\n",
    "width_std = df_props['width'].std()\n",
    "height_std = df_props['height'].std()\n",
    "\n",
    "print(\"\\n⚠️  INCONSISTENCY CHECK:\")\n",
    "if width_std > 100 or height_std > 100:\n",
    "    print(f\"   WARNING: High variation in dimensions detected!\")\n",
    "    print(f\"   Width std: {width_std:.1f}, Height std: {height_std:.1f}\")\n",
    "    print(\"\\n   🔧 RECOMMENDATION: Resize all images to a consistent size\")\n",
    "    print(f\"   Suggested target size: {int(df_props['width'].median())}x{int(df_props['height'].median())}\")\n",
    "else:\n",
    "    print(\"   ✓ Dimensions are relatively consistent across images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rgb_statistics(data_dict, sample_size=50):\n",
    "    \"\"\"\n",
    "    Compute RGB channel statistics per class.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        sample_size: Number of images to sample per class\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with mean and std for each channel per class\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    for cls, img_paths in data_dict.items():\n",
    "        paths_to_analyze = random.sample(img_paths, min(sample_size, len(img_paths)))\n",
    "        \n",
    "        all_pixels = {'R': [], 'G': [], 'B': []}\n",
    "        \n",
    "        for img_path in paths_to_analyze:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Sample pixels (to avoid memory issues)\n",
    "                h, w = img_array.shape[:2]\n",
    "                sample_pixels = img_array[::max(1, h//100), ::max(1, w//100), :]\n",
    "                \n",
    "                all_pixels['R'].extend(sample_pixels[:, :, 0].flatten())\n",
    "                all_pixels['G'].extend(sample_pixels[:, :, 1].flatten())\n",
    "                all_pixels['B'].extend(sample_pixels[:, :, 2].flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "        \n",
    "        stats[cls] = {\n",
    "            'R_mean': np.mean(all_pixels['R']),\n",
    "            'R_std': np.std(all_pixels['R']),\n",
    "            'G_mean': np.mean(all_pixels['G']),\n",
    "            'G_std': np.std(all_pixels['G']),\n",
    "            'B_mean': np.mean(all_pixels['B']),\n",
    "            'B_std': np.std(all_pixels['B']),\n",
    "        }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Compute RGB statistics\n",
    "print(\"Computing RGB channel statistics (this may take a moment)...\")\n",
    "rgb_stats = compute_rgb_statistics(train_data, sample_size=50)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RGB CHANNEL STATISTICS (for normalization)\")\n",
    "print(\"=\"*60)\n",
    "for cls in CLASSES:\n",
    "    print(f\"\\n{cls.upper()}:\")\n",
    "    print(f\"   R: μ={rgb_stats[cls]['R_mean']:.2f}, σ={rgb_stats[cls]['R_std']:.2f}\")\n",
    "    print(f\"   G: μ={rgb_stats[cls]['G_mean']:.2f}, σ={rgb_stats[cls]['G_std']:.2f}\")\n",
    "    print(f\"   B: μ={rgb_stats[cls]['B_mean']:.2f}, σ={rgb_stats[cls]['B_std']:.2f}\")\n",
    "\n",
    "# Compute global statistics\n",
    "global_R_mean = np.mean([rgb_stats[cls]['R_mean'] for cls in CLASSES])\n",
    "global_G_mean = np.mean([rgb_stats[cls]['G_mean'] for cls in CLASSES])\n",
    "global_B_mean = np.mean([rgb_stats[cls]['B_mean'] for cls in CLASSES])\n",
    "global_R_std = np.mean([rgb_stats[cls]['R_std'] for cls in CLASSES])\n",
    "global_G_std = np.mean([rgb_stats[cls]['G_std'] for cls in CLASSES])\n",
    "global_B_std = np.mean([rgb_stats[cls]['B_std'] for cls in CLASSES])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GLOBAL STATISTICS (recommended for normalization):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mean: [{global_R_mean/255:.4f}, {global_G_mean/255:.4f}, {global_B_mean/255:.4f}]\")\n",
    "print(f\"Std:  [{global_R_std/255:.4f}, {global_G_std/255:.4f}, {global_B_std/255:.4f}]\")\n",
    "print(\"\\n💡 Use these values for input normalization in your CNN\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afff71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RGB intensity distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "channels = ['R', 'G', 'B']\n",
    "channel_names = ['Red', 'Green', 'Blue']\n",
    "\n",
    "for idx, (ch, ch_name) in enumerate(zip(channels, channel_names)):\n",
    "    means = [rgb_stats[cls][f'{ch}_mean'] for cls in CLASSES]\n",
    "    stds = [rgb_stats[cls][f'{ch}_std'] for cls in CLASSES]\n",
    "    \n",
    "    x = np.arange(len(CLASSES))\n",
    "    axes[idx].bar(x, means, yerr=stds, alpha=0.7, \n",
    "                  color=[CLASS_COLORS[cls] for cls in CLASSES],\n",
    "                  edgecolor='black', capsize=5)\n",
    "    axes[idx].set_title(f'{ch_name} Channel Intensity', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Class')\n",
    "    axes[idx].set_ylabel('Pixel Intensity (0-255)')\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(CLASSES)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    axes[idx].set_ylim(0, 255)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f28406",
   "metadata": {},
   "source": [
    "## 3. VISUAL INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_grid(data_dict, samples_per_class=5, figsize=(18, 10)):\n",
    "    \"\"\"\n",
    "    Display a grid of sample images from each class.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        samples_per_class: Number of samples to display per class\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(CLASSES), samples_per_class, figsize=figsize)\n",
    "    \n",
    "    for row_idx, cls in enumerate(CLASSES):\n",
    "        # Randomly sample images\n",
    "        sample_paths = random.sample(data_dict[cls], min(samples_per_class, len(data_dict[cls])))\n",
    "        \n",
    "        for col_idx, img_path in enumerate(sample_paths):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                axes[row_idx, col_idx].imshow(img)\n",
    "                axes[row_idx, col_idx].axis('off')\n",
    "                \n",
    "                if col_idx == 0:\n",
    "                    axes[row_idx, col_idx].set_ylabel(cls.upper(), \n",
    "                                                       fontsize=12, \n",
    "                                                       fontweight='bold',\n",
    "                                                       rotation=0, \n",
    "                                                       labelpad=40,\n",
    "                                                       va='center')\n",
    "            except Exception as e:\n",
    "                print(f\"Error displaying {img_path}: {e}\")\n",
    "    \n",
    "    plt.suptitle('Random Sample Images from Each Class', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample grid\n",
    "print(\"Displaying sample images...\")\n",
    "display_sample_grid(train_data, samples_per_class=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68252612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_edge_detection(data_dict, samples_per_class=3):\n",
    "    \"\"\"\n",
    "    Apply Canny edge detection to assess texture separability.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        samples_per_class: Number of samples to process per class\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(CLASSES), samples_per_class * 2, figsize=(18, 10))\n",
    "    \n",
    "    for row_idx, cls in enumerate(CLASSES):\n",
    "        sample_paths = random.sample(data_dict[cls], min(samples_per_class, len(data_dict[cls])))\n",
    "        \n",
    "        for col_idx, img_path in enumerate(sample_paths):\n",
    "            try:\n",
    "                # Load and convert to grayscale\n",
    "                img = cv2.imread(str(img_path))\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Apply Canny edge detection\n",
    "                edges = cv2.Canny(img_gray, 50, 150)\n",
    "                \n",
    "                # Display original\n",
    "                axes[row_idx, col_idx * 2].imshow(img_rgb)\n",
    "                axes[row_idx, col_idx * 2].axis('off')\n",
    "                \n",
    "                # Display edges\n",
    "                axes[row_idx, col_idx * 2 + 1].imshow(edges, cmap='gray')\n",
    "                axes[row_idx, col_idx * 2 + 1].axis('off')\n",
    "                \n",
    "                if col_idx == 0:\n",
    "                    axes[row_idx, 0].set_ylabel(cls.upper(), \n",
    "                                                fontsize=12, \n",
    "                                                fontweight='bold',\n",
    "                                                rotation=0, \n",
    "                                                labelpad=40,\n",
    "                                                va='center')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    plt.suptitle('Edge Detection (Canny) - Original vs Edges', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply edge detection\n",
    "print(\"Applying edge detection...\")\n",
    "apply_edge_detection(train_data, samples_per_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3640d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gabor_filters(img_gray, orientations=[0, 45, 90, 135]):\n",
    "    \"\"\"\n",
    "    Apply Gabor filters at different orientations to highlight textures.\n",
    "    \n",
    "    Args:\n",
    "        img_gray: Grayscale image\n",
    "        orientations: List of filter orientations in degrees\n",
    "    \n",
    "    Returns:\n",
    "        Combined filtered image\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    for theta in orientations:\n",
    "        theta_rad = theta / 180.0 * np.pi\n",
    "        kernel = cv2.getGaborKernel((21, 21), 5, theta_rad, 10, 0.5, 0, ktype=cv2.CV_32F)\n",
    "        filtered = cv2.filter2D(img_gray, cv2.CV_8UC3, kernel)\n",
    "        filters.append(filtered)\n",
    "    \n",
    "    # Combine all orientations\n",
    "    combined = np.max(filters, axis=0)\n",
    "    return combined\n",
    "\n",
    "def display_gabor_analysis(data_dict, samples_per_class=2):\n",
    "    \"\"\"\n",
    "    Display Gabor filter analysis for texture detection.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(CLASSES), samples_per_class * 2, figsize=(16, 10))\n",
    "    \n",
    "    for row_idx, cls in enumerate(CLASSES):\n",
    "        sample_paths = random.sample(data_dict[cls], min(samples_per_class, len(data_dict[cls])))\n",
    "        \n",
    "        for col_idx, img_path in enumerate(sample_paths):\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Apply Gabor filters\n",
    "                gabor_result = apply_gabor_filters(img_gray)\n",
    "                \n",
    "                # Display original\n",
    "                axes[row_idx, col_idx * 2].imshow(img_rgb)\n",
    "                axes[row_idx, col_idx * 2].axis('off')\n",
    "                \n",
    "                # Display Gabor result\n",
    "                axes[row_idx, col_idx * 2 + 1].imshow(gabor_result, cmap='hot')\n",
    "                axes[row_idx, col_idx * 2 + 1].axis('off')\n",
    "                \n",
    "                if col_idx == 0:\n",
    "                    axes[row_idx, 0].set_ylabel(cls.upper(), \n",
    "                                                fontsize=12, \n",
    "                                                fontweight='bold',\n",
    "                                                rotation=0, \n",
    "                                                labelpad=40,\n",
    "                                                va='center')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    plt.suptitle('Gabor Filter Analysis - Original vs Texture Response', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply Gabor filter analysis\n",
    "print(\"Applying Gabor filter analysis...\")\n",
    "display_gabor_analysis(train_data, samples_per_class=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8367b",
   "metadata": {},
   "source": [
    "## 4. COLOR & SPECTRAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_features(data_dict, sample_size=30, pixels_per_image=1000):\n",
    "    \"\"\"\n",
    "    Extract RGB pixel values from images for color space analysis.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        sample_size: Number of images to sample per class\n",
    "        pixels_per_image: Number of pixels to sample per image\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with RGB values and class labels\n",
    "    \"\"\"\n",
    "    color_data = []\n",
    "    \n",
    "    for cls, img_paths in data_dict.items():\n",
    "        paths_to_analyze = random.sample(img_paths, min(sample_size, len(img_paths)))\n",
    "        \n",
    "        for img_path in paths_to_analyze:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Flatten and sample pixels\n",
    "                h, w = img_array.shape[:2]\n",
    "                pixels = img_array.reshape(-1, 3)\n",
    "                \n",
    "                # Random sample\n",
    "                if len(pixels) > pixels_per_image:\n",
    "                    indices = np.random.choice(len(pixels), pixels_per_image, replace=False)\n",
    "                    pixels = pixels[indices]\n",
    "                \n",
    "                for pixel in pixels:\n",
    "                    color_data.append({\n",
    "                        'class': cls,\n",
    "                        'R': pixel[0],\n",
    "                        'G': pixel[1],\n",
    "                        'B': pixel[2]\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(color_data)\n",
    "\n",
    "# Extract color features\n",
    "print(\"Extracting color features for RGB space analysis...\")\n",
    "df_colors = extract_color_features(train_data, sample_size=30, pixels_per_image=500)\n",
    "print(f\"Extracted {len(df_colors)} pixel samples\")\n",
    "print(df_colors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RGB scatter plots\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# R vs G\n",
    "ax1 = fig.add_subplot(2, 3, 1)\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_colors[df_colors['class'] == cls].sample(min(1000, len(df_colors[df_colors['class'] == cls])))\n",
    "    ax1.scatter(cls_data['R'], cls_data['G'], alpha=0.3, s=1, label=cls, color=CLASS_COLORS[cls])\n",
    "ax1.set_xlabel('Red Channel')\n",
    "ax1.set_ylabel('Green Channel')\n",
    "ax1.set_title('R vs G Channel', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# R vs B\n",
    "ax2 = fig.add_subplot(2, 3, 2)\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_colors[df_colors['class'] == cls].sample(min(1000, len(df_colors[df_colors['class'] == cls])))\n",
    "    ax2.scatter(cls_data['R'], cls_data['B'], alpha=0.3, s=1, label=cls, color=CLASS_COLORS[cls])\n",
    "ax2.set_xlabel('Red Channel')\n",
    "ax2.set_ylabel('Blue Channel')\n",
    "ax2.set_title('R vs B Channel', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# G vs B\n",
    "ax3 = fig.add_subplot(2, 3, 3)\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_colors[df_colors['class'] == cls].sample(min(1000, len(df_colors[df_colors['class'] == cls])))\n",
    "    ax3.scatter(cls_data['G'], cls_data['B'], alpha=0.3, s=1, label=cls, color=CLASS_COLORS[cls])\n",
    "ax3.set_xlabel('Green Channel')\n",
    "ax3.set_ylabel('Blue Channel')\n",
    "ax3.set_title('G vs B Channel', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 2D density plots\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "for idx, cls in enumerate(CLASSES):\n",
    "    ax = fig.add_subplot(2, 3, 4 + idx)\n",
    "    cls_data = df_colors[df_colors['class'] == cls].sample(min(2000, len(df_colors[df_colors['class'] == cls])))\n",
    "    \n",
    "    # Create 2D histogram\n",
    "    h, xedges, yedges = np.histogram2d(cls_data['R'], cls_data['G'], bins=50)\n",
    "    ax.imshow(h.T, origin='lower', extent=[0, 255, 0, 255], cmap='hot', aspect='auto')\n",
    "    ax.set_xlabel('Red Channel')\n",
    "    ax.set_ylabel('Green Channel')\n",
    "    ax.set_title(f'{cls.upper()} - R vs G Density', fontweight='bold')\n",
    "\n",
    "plt.suptitle('RGB Color Space Analysis', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze color space separability\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLOR SPACE SEPARABILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_colors[df_colors['class'] == cls]\n",
    "    print(f\"\\n{cls.upper()}:\")\n",
    "    print(f\"   R: {cls_data['R'].mean():.1f} ± {cls_data['R'].std():.1f}\")\n",
    "    print(f\"   G: {cls_data['G'].mean():.1f} ± {cls_data['G'].std():.1f}\")\n",
    "    print(f\"   B: {cls_data['B'].mean():.1f} ± {cls_data['B'].std():.1f}\")\n",
    "    print(f\"   R/G ratio: {(cls_data['R'] / (cls_data['G'] + 1)).mean():.3f}\")\n",
    "    print(f\"   B/G ratio: {(cls_data['B'] / (cls_data['G'] + 1)).mean():.3f}\")\n",
    "\n",
    "# Check for overlap\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERLAP ASSESSMENT:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute pairwise distance between class centroids in RGB space\n",
    "centroids = {}\n",
    "for cls in CLASSES:\n",
    "    cls_data = df_colors[df_colors['class'] == cls]\n",
    "    centroids[cls] = np.array([\n",
    "        cls_data['R'].mean(),\n",
    "        cls_data['G'].mean(),\n",
    "        cls_data['B'].mean()\n",
    "    ])\n",
    "\n",
    "print(\"\\nCentroid distances in RGB space:\")\n",
    "for i, cls1 in enumerate(CLASSES):\n",
    "    for cls2 in CLASSES[i+1:]:\n",
    "        dist = np.linalg.norm(centroids[cls1] - centroids[cls2])\n",
    "        print(f\"   {cls1} <-> {cls2}: {dist:.2f}\")\n",
    "\n",
    "print(\"\\n💡 INSIGHT:\")\n",
    "print(\"   - Smaller distances indicate more overlap in RGB space\")\n",
    "print(\"   - Classes with distance < 30 may be hard to separate using color alone\")\n",
    "print(\"   - Consider texture/spatial features for better discrimination\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59520ae",
   "metadata": {},
   "source": [
    "## 5. SPATIAL PATTERNS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_image(data_dict, target_size=(224, 224), sample_size=50):\n",
    "    \"\"\"\n",
    "    Compute the average image for each class to detect spatial patterns.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        target_size: Size to resize images to before averaging\n",
    "        sample_size: Number of images to use per class\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with class names and average images\n",
    "    \"\"\"\n",
    "    avg_images = {}\n",
    "    \n",
    "    for cls, img_paths in data_dict.items():\n",
    "        paths_to_use = random.sample(img_paths, min(sample_size, len(img_paths)))\n",
    "        \n",
    "        accumulated = np.zeros((*target_size, 3), dtype=np.float32)\n",
    "        count = 0\n",
    "        \n",
    "        for img_path in paths_to_use:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_resized = img.resize(target_size)\n",
    "                img_array = np.array(img_resized, dtype=np.float32)\n",
    "                accumulated += img_array\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "        \n",
    "        if count > 0:\n",
    "            avg_images[cls] = (accumulated / count).astype(np.uint8)\n",
    "    \n",
    "    return avg_images\n",
    "\n",
    "# Compute average images\n",
    "print(\"Computing average images per class...\")\n",
    "avg_images = compute_average_image(train_data, target_size=(224, 224), sample_size=50)\n",
    "\n",
    "# Display average images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, cls in enumerate(CLASSES):\n",
    "    axes[idx].imshow(avg_images[cls])\n",
    "    axes[idx].set_title(f'{cls.upper()} - Average Image', fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Average Images by Class (Pixel-wise Mean)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 SPATIAL PATTERN OBSERVATIONS:\")\n",
    "print(\"   - Look for consistent patterns in specific regions\")\n",
    "print(\"   - Haze/smoke might appear more in upper portions (sky)\")\n",
    "print(\"   - Normal images might have more distinct ground features\")\n",
    "print(\"   - Consistent patterns suggest positional bias in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spatial distribution (where haze/smoke typically appears)\n",
    "def analyze_spatial_distribution(avg_images):\n",
    "    \"\"\"\n",
    "    Analyze where features concentrate in average images.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    for idx, cls in enumerate(CLASSES):\n",
    "        # Convert to grayscale for intensity analysis\n",
    "        gray = cv2.cvtColor(avg_images[cls], cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Display grayscale average\n",
    "        axes[0, idx].imshow(gray, cmap='gray')\n",
    "        axes[0, idx].set_title(f'{cls.upper()} - Grayscale', fontweight='bold')\n",
    "        axes[0, idx].axis('off')\n",
    "        \n",
    "        # Compute and display vertical profile (average intensity per row)\n",
    "        vertical_profile = gray.mean(axis=1)\n",
    "        horizontal_profile = gray.mean(axis=0)\n",
    "        \n",
    "        # Horizontal profile plot (top to bottom)\n",
    "        axes[1, idx].plot(vertical_profile, range(len(vertical_profile)), linewidth=2, color=CLASS_COLORS[cls])\n",
    "        axes[1, idx].set_title(f'{cls.upper()} - Vertical Intensity Profile', fontweight='bold')\n",
    "        axes[1, idx].set_xlabel('Mean Intensity')\n",
    "        axes[1, idx].set_ylabel('Row (Top to Bottom)')\n",
    "        axes[1, idx].invert_yaxis()\n",
    "        axes[1, idx].grid(alpha=0.3)\n",
    "        axes[1, idx].axvline(x=vertical_profile.mean(), color='red', linestyle='--', label='Mean')\n",
    "        axes[1, idx].legend()\n",
    "    \n",
    "    plt.suptitle('Spatial Intensity Distribution Analysis', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_spatial_distribution(avg_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f23e52",
   "metadata": {},
   "source": [
    "## 6. AUGMENTATION PREVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464dc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentations(img):\n",
    "    \"\"\"\n",
    "    Apply various augmentations to a single image.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of augmented images\n",
    "    \"\"\"\n",
    "    img_array = np.array(img)\n",
    "    augmented = {}\n",
    "    \n",
    "    # Original\n",
    "    augmented['Original'] = img_array\n",
    "    \n",
    "    # Rotation\n",
    "    augmented['Rotate 15°'] = np.array(img.rotate(15))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    augmented['Horizontal Flip'] = np.array(img.transpose(Image.FLIP_LEFT_RIGHT))\n",
    "    \n",
    "    # Vertical flip\n",
    "    augmented['Vertical Flip'] = np.array(img.transpose(Image.FLIP_TOP_BOTTOM))\n",
    "    \n",
    "    # Brightness adjustment\n",
    "    from PIL import ImageEnhance\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    augmented['Brightness +30%'] = np.array(enhancer.enhance(1.3))\n",
    "    \n",
    "    # Contrast adjustment\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    augmented['Contrast +30%'] = np.array(enhancer.enhance(1.3))\n",
    "    \n",
    "    # Gaussian noise\n",
    "    noisy = img_array.astype(np.float32)\n",
    "    noise = np.random.normal(0, 15, img_array.shape)\n",
    "    noisy = np.clip(noisy + noise, 0, 255).astype(np.uint8)\n",
    "    augmented['Gaussian Noise'] = noisy\n",
    "    \n",
    "    # Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(img_array, (5, 5), 0)\n",
    "    augmented['Gaussian Blur'] = blurred\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "# Select random sample from each class\n",
    "sample_images = {}\n",
    "for cls in CLASSES:\n",
    "    sample_path = random.choice(train_data[cls])\n",
    "    sample_images[cls] = Image.open(sample_path).convert('RGB')\n",
    "\n",
    "# Display augmentations for one image from each class\n",
    "for cls in CLASSES:\n",
    "    augmented = apply_augmentations(sample_images[cls])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (aug_name, aug_img) in enumerate(augmented.items()):\n",
    "        axes[idx].imshow(aug_img)\n",
    "        axes[idx].set_title(aug_name, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Augmentation Preview - {cls.upper()} Class', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AUGMENTATION STRATEGY RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ SAFE AUGMENTATIONS (preserve class semantics):\")\n",
    "print(\"   1. Horizontal Flip - Safe for satellite imagery\")\n",
    "print(\"   2. Rotation ±15° - Maintains atmospheric conditions\")\n",
    "print(\"   3. Brightness ±20% - Simulates different lighting\")\n",
    "print(\"   4. Contrast ±20% - Enhances feature visibility\")\n",
    "print(\"   5. Slight Gaussian Noise - Simulates sensor noise\")\n",
    "\n",
    "print(\"\\n⚠️  USE WITH CAUTION:\")\n",
    "print(\"   1. Heavy blur - May make haze/smoke indistinguishable\")\n",
    "print(\"   2. Extreme brightness - Can wash out haze/smoke features\")\n",
    "print(\"   3. Color jitter - Might confuse haze vs smoke separation\")\n",
    "print(\"   4. Vertical flip - Less natural for satellite imagery\")\n",
    "\n",
    "print(\"\\n🔧 RECOMMENDED STRATEGY:\")\n",
    "print(\"   - Apply moderate augmentations to minority classes\")\n",
    "print(\"   - Use MixUp or CutMix for better generalization\")\n",
    "print(\"   - Avoid augmentations that create class ambiguity\")\n",
    "print(\"   - Test augmentations on validation set to ensure they help\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3784e",
   "metadata": {},
   "source": [
    "## 7. CONFUSION & AMBIGUITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524347b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"POTENTIAL CONFUSION PATTERNS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n🔍 EXPECTED CONFUSION PAIRS:\")\n",
    "print(\"\\n1. HAZE vs SMOKE:\")\n",
    "print(\"   - Both create atmospheric obscuration\")\n",
    "print(\"   - Both may appear as white/gray patterns\")\n",
    "print(\"   - Smoke might have more defined edges/plumes\")\n",
    "print(\"   - Haze is typically more uniform and diffuse\")\n",
    "\n",
    "print(\"\\n2. HAZE vs NORMAL (with clouds):\")\n",
    "print(\"   - Clouds can be mistaken for haze\")\n",
    "print(\"   - Both appear white/light gray\")\n",
    "print(\"   - Haze affects entire image uniformly\")\n",
    "print(\"   - Clouds have more distinct boundaries\")\n",
    "\n",
    "print(\"\\n3. SMOKE vs NORMAL:\")\n",
    "print(\"   - Less likely to confuse\")\n",
    "print(\"   - Smoke has distinctive plume patterns\")\n",
    "print(\"   - Normal images have clearer ground features\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRELIMINARY CONFUSION MATRIX (Visual Inspection)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n              Predicted\")\n",
    "print(\"Actual        Normal  Haze  Smoke\")\n",
    "print(\"Normal        ████    ░░    ░\")\n",
    "print(\"Haze          ░░      ███   ██\")\n",
    "print(\"Smoke         ░       ██    ███\")\n",
    "print(\"\\nLegend: ████ High confidence | ███ Medium | ██ Low | ░ Very Low\")\n",
    "\n",
    "print(\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(\"   1. Focus on haze vs smoke discrimination\")\n",
    "print(\"   2. Use texture features (Gabor, edge density)\")\n",
    "print(\"   3. Consider ensemble models or attention mechanisms\")\n",
    "print(\"   4. Hard-negative mining during training\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display potentially ambiguous samples for manual inspection\n",
    "# In practice, you would manually review and flag these\n",
    "print(\"\\n🔍 SAMPLE IMAGES FOR MANUAL AMBIGUITY ASSESSMENT:\")\n",
    "print(\"   (In production, manually review and create a challenge set)\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(18, 10))\n",
    "\n",
    "for row_idx, cls in enumerate(CLASSES):\n",
    "    # Select 5 random samples that might be ambiguous\n",
    "    # In practice, you'd manually select hard examples\n",
    "    sample_paths = random.sample(train_data[cls], min(5, len(train_data[cls])))\n",
    "    \n",
    "    for col_idx, img_path in enumerate(sample_paths):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            axes[row_idx, col_idx].imshow(img)\n",
    "            axes[row_idx, col_idx].axis('off')\n",
    "            axes[row_idx, col_idx].set_title(f'{cls}', fontsize=10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "plt.suptitle('Sample Images for Manual Ambiguity Review', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 TODO: Manually review these and flag ambiguous cases for:\")\n",
    "print(\"   - Creating a challenge validation set\")\n",
    "print(\"   - Hard-negative mining during training\")\n",
    "print(\"   - Understanding model failure modes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eab33c",
   "metadata": {},
   "source": [
    "## 8. DATASET SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_stratified_splits(data_dict, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Create stratified train/val/test splits.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with class names and image paths\n",
    "        val_size: Validation set proportion\n",
    "        test_size: Test set proportion\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with split information\n",
    "    \"\"\"\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for cls, paths in data_dict.items():\n",
    "        all_paths.extend(paths)\n",
    "        all_labels.extend([cls] * len(paths))\n",
    "    \n",
    "    # First split: separate test set\n",
    "    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "        all_paths, all_labels, \n",
    "        test_size=test_size, \n",
    "        stratify=all_labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: separate validation set from training\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_val_paths, train_val_labels,\n",
    "        test_size=val_size_adjusted,\n",
    "        stratify=train_val_labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    splits = {\n",
    "        'train': {'paths': train_paths, 'labels': train_labels},\n",
    "        'val': {'paths': val_paths, 'labels': val_labels},\n",
    "        'test': {'paths': test_paths, 'labels': test_labels}\n",
    "    }\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Create splits\n",
    "print(\"Creating stratified train/val/test splits...\")\n",
    "splits = create_stratified_splits(train_data, val_size=0.15, test_size=0.15)\n",
    "\n",
    "# Analyze splits\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SPLIT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "split_summary = []\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_data = splits[split_name]\n",
    "    total = len(split_data['labels'])\n",
    "    \n",
    "    class_counts = {cls: split_data['labels'].count(cls) for cls in CLASSES}\n",
    "    \n",
    "    print(f\"\\n{split_name.upper()} SET ({total} samples):\")\n",
    "    for cls in CLASSES:\n",
    "        count = class_counts[cls]\n",
    "        pct = count / total * 100\n",
    "        print(f\"   {cls:10s}: {count:4d} ({pct:5.2f}%)\")\n",
    "    \n",
    "    split_summary.append({\n",
    "        'Split': split_name,\n",
    "        'Total': total,\n",
    "        **class_counts\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_splits = pd.DataFrame(split_summary)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPLIT COMPARISON TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(df_splits.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize split distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "\n",
    "x = np.arange(len(CLASSES))\n",
    "width = 0.25\n",
    "\n",
    "for idx, split_name in enumerate(['train', 'val', 'test']):\n",
    "    counts = [df_splits[df_splits['Split'] == split_name][cls].values[0] for cls in CLASSES]\n",
    "    ax.bar(x + idx * width, counts, width, label=split_name.upper(), alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "ax.set_title('Dataset Split Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(CLASSES)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ SPLIT STRATEGY:\")\n",
    "print(\"   - Stratified sampling maintains class proportions\")\n",
    "print(\"   - 70% training, 15% validation, 15% test\")\n",
    "print(\"   - Use validation set for hyperparameter tuning\")\n",
    "print(\"   - Hold out test set for final evaluation only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4b1b6",
   "metadata": {},
   "source": [
    "## 9. SUMMARY & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c85c7d",
   "metadata": {},
   "source": [
    "### 📊 KEY FINDINGS\n",
    "\n",
    "Based on the comprehensive EDA performed above, here are the critical insights:\n",
    "\n",
    "#### 1. **Dataset Characteristics**\n",
    "- **Class Distribution**: Review the balance analysis from Section 1\n",
    "- **Image Dimensions**: Check consistency and variation in image sizes\n",
    "- **Color Statistics**: RGB channel means and standard deviations computed for normalization\n",
    "\n",
    "#### 2. **Discriminative Features**\n",
    "- **Color Space**: Classes may overlap in RGB space - texture features are critical\n",
    "- **Spatial Patterns**: Haze/smoke may concentrate in specific image regions (typically upper portions)\n",
    "- **Texture**: Edge detection and Gabor filters show potential for class separation\n",
    "\n",
    "#### 3. **Challenges**\n",
    "- **Haze vs Smoke Confusion**: Most likely confusion pair due to visual similarity\n",
    "- **Cloud Interference**: Normal images with clouds may be mistaken for haze\n",
    "- **Class Overlap**: Color alone insufficient - need spatial/texture features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b1342",
   "metadata": {},
   "source": [
    "### 🏗️ CNN ARCHITECTURE RECOMMENDATIONS\n",
    "\n",
    "#### **Option 1: Lightweight CNN (Prioritize Throughput & Size)**\n",
    "```\n",
    "Best for: Fast inference, edge deployment, small model size\n",
    "\n",
    "Architecture:\n",
    "- 4-5 Convolutional blocks\n",
    "- Depthwise separable convolutions (like MobileNet)\n",
    "- Global average pooling instead of FC layers\n",
    "- Dropout (0.3-0.5) for regularization\n",
    "\n",
    "Target size: < 5MB\n",
    "Expected throughput: > 100 images/sec (GPU)\n",
    "```\n",
    "\n",
    "#### **Option 2: Transfer Learning (Prioritize F1 Score)**\n",
    "```\n",
    "Best for: Maximum accuracy with reasonable size\n",
    "\n",
    "Recommended backbones:\n",
    "- EfficientNetB0/B1 (good balance)\n",
    "- ResNet50 (proven performance)\n",
    "- MobileNetV3 (lightweight but effective)\n",
    "\n",
    "Strategy:\n",
    "- Freeze early layers initially\n",
    "- Fine-tune last 2-3 blocks\n",
    "- Add custom classification head\n",
    "- Use gradual unfreezing\n",
    "```\n",
    "\n",
    "#### **Option 3: Hybrid Attention Model (Balanced)**\n",
    "```\n",
    "Best for: Handling ambiguous cases (haze vs smoke)\n",
    "\n",
    "Components:\n",
    "- Lightweight backbone (EfficientNetB0)\n",
    "- Spatial attention module (CBAM/SE blocks)\n",
    "- Multi-scale feature extraction\n",
    "- Focal loss for hard examples\n",
    "\n",
    "Benefits:\n",
    "- Focuses on discriminative regions\n",
    "- Better haze/smoke separation\n",
    "- Moderate size increase\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a2305",
   "metadata": {},
   "source": [
    "### 🔧 PREPROCESSING RECOMMENDATIONS\n",
    "\n",
    "#### **1. Image Resizing**\n",
    "```python\n",
    "# Recommended target size based on analysis\n",
    "TARGET_SIZE = (224, 224)  # Standard for most pre-trained models\n",
    "# Alternative: (192, 192) for faster inference with minimal accuracy loss\n",
    "\n",
    "# Resize strategy\n",
    "- Use PIL.Image.LANCZOS for best quality\n",
    "- Maintain aspect ratio with padding if needed\n",
    "- Or use center crop for speed\n",
    "```\n",
    "\n",
    "#### **2. Normalization**\n",
    "```python\n",
    "# Use the global statistics computed in Section 2\n",
    "# Example values (replace with actual from your data):\n",
    "MEAN = [0.485, 0.456, 0.406]  # Update from Section 2 output\n",
    "STD = [0.229, 0.224, 0.225]   # Update from Section 2 output\n",
    "\n",
    "# Apply normalization\n",
    "normalize = transforms.Normalize(mean=MEAN, std=STD)\n",
    "```\n",
    "\n",
    "#### **3. Data Augmentation Pipeline**\n",
    "```python\n",
    "# Training augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Validation/Test (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971809db",
   "metadata": {},
   "source": [
    "### 📉 LOSS FUNCTION RECOMMENDATIONS\n",
    "\n",
    "#### **Option 1: Weighted Cross-Entropy** ✅ RECOMMENDED\n",
    "```python\n",
    "# Best for: Moderate class imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor(class_weights, dtype=torch.float)\n",
    ")\n",
    "```\n",
    "\n",
    "#### **Option 2: Focal Loss** (If severe imbalance detected)\n",
    "```python\n",
    "# Best for: Hard example mining, severe imbalance\n",
    "# Focuses on misclassified examples\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "```\n",
    "\n",
    "#### **Option 3: Label Smoothing Cross-Entropy**\n",
    "```python\n",
    "# Best for: Reducing overconfidence, improving generalization\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# Helps with ambiguous haze/smoke cases\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bc591",
   "metadata": {},
   "source": [
    "### 🎯 TRAINING STRATEGY\n",
    "\n",
    "#### **Hyperparameters**\n",
    "```python\n",
    "# Recommended starting points\n",
    "BATCH_SIZE = 32  # Adjust based on GPU memory\n",
    "LEARNING_RATE = 1e-4  # For transfer learning\n",
    "EPOCHS = 50\n",
    "PATIENCE = 10  # For early stopping\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "# Alternative: ReduceLROnPlateau for adaptive reduction\n",
    "```\n",
    "\n",
    "#### **Training Techniques**\n",
    "1. **Early Stopping**: Monitor validation F1 score, stop if no improvement for 10 epochs\n",
    "2. **Model Checkpointing**: Save best model based on validation weighted F1\n",
    "3. **Mixed Precision Training**: Use `torch.cuda.amp` for faster training\n",
    "4. **Gradient Clipping**: Prevent exploding gradients (clip at 1.0)\n",
    "5. **Progressive Resizing**: Start with 128x128, then 192x192, finally 224x224\n",
    "\n",
    "#### **Evaluation Metrics**\n",
    "```python\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Primary metric\n",
    "weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Per-class analysis\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e2b58",
   "metadata": {},
   "source": [
    "### ⚡ OPTIMIZATION FOR HACKATHON METRICS\n",
    "\n",
    "#### **Weighted F1 Score** (Primary)\n",
    "- Use stratified validation sets\n",
    "- Monitor per-class F1 scores\n",
    "- Apply class weights if imbalance detected\n",
    "- Use confusion matrix to identify weak pairs (haze vs smoke)\n",
    "- Consider ensemble of 3-5 models for final submission\n",
    "\n",
    "#### **Model Throughput** (Secondary)\n",
    "```python\n",
    "# Optimization techniques\n",
    "1. Model Quantization (Post-training):\n",
    "   - Convert to INT8 using PyTorch's quantization\n",
    "   - 4x speedup with minimal accuracy loss\n",
    "\n",
    "2. TensorRT Optimization:\n",
    "   - Convert to ONNX then TensorRT\n",
    "   - Optimize for target hardware\n",
    "\n",
    "3. Pruning:\n",
    "   - Remove redundant weights\n",
    "   - Can achieve 30-50% size reduction\n",
    "\n",
    "# Measure throughput\n",
    "import time\n",
    "def measure_throughput(model, batch_size=32, num_batches=100):\n",
    "    dummy_input = torch.randn(batch_size, 3, 224, 224).cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_batches):\n",
    "            _ = model(dummy_input)\n",
    "    end = time.time()\n",
    "    \n",
    "    images_per_sec = (batch_size * num_batches) / (end - start)\n",
    "    return images_per_sec\n",
    "```\n",
    "\n",
    "#### **Model Size** (Tertiary)\n",
    "```python\n",
    "# Target: < 20MB for good score\n",
    "# Techniques:\n",
    "1. Use MobileNetV3 or EfficientNetB0 backbone\n",
    "2. Reduce final FC layer dimensions\n",
    "3. Use knowledge distillation from larger model\n",
    "4. Prune and quantize\n",
    "\n",
    "# Measure model size\n",
    "def get_model_size(model):\n",
    "    torch.save(model.state_dict(), \"temp.pth\")\n",
    "    size_mb = os.path.getsize(\"temp.pth\") / (1024 * 1024)\n",
    "    os.remove(\"temp.pth\")\n",
    "    return size_mb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3500f19",
   "metadata": {},
   "source": [
    "### 🚀 FINAL RECOMMENDATIONS SUMMARY\n",
    "\n",
    "#### **IMMEDIATE NEXT STEPS:**\n",
    "\n",
    "1. **Model Selection** (Choose one):\n",
    "   - **RECOMMENDED**: EfficientNetB0 with transfer learning\n",
    "     - Best balance of F1, size, and throughput\n",
    "     - Pre-trained on ImageNet helps with general features\n",
    "   \n",
    "2. **Preprocessing**:\n",
    "   - Resize to 224x224\n",
    "   - Apply normalization with computed statistics from Section 2\n",
    "   - Use stratified splits from Section 8\n",
    "\n",
    "3. **Training Configuration**:\n",
    "   - Loss: Weighted Cross-Entropy (check imbalance from Section 1)\n",
    "   - Optimizer: AdamW with lr=1e-4\n",
    "   - Augmentation: Moderate (horizontal flip, rotation ±15°, brightness/contrast)\n",
    "   - Batch size: 32\n",
    "   - Early stopping on validation F1\n",
    "\n",
    "4. **Evaluation & Iteration**:\n",
    "   - Monitor confusion matrix (focus on haze vs smoke)\n",
    "   - If F1 < 0.85, try Focal Loss or attention modules\n",
    "   - If throughput low, try MobileNetV3 or quantization\n",
    "   - If size too large, apply pruning\n",
    "\n",
    "#### **EXPECTED PERFORMANCE TARGETS:**\n",
    "```\n",
    "Weighted F1 Score: > 0.90 (achievable with EfficientNetB0)\n",
    "Throughput: > 50 images/sec (GPU), > 10 images/sec (CPU with quantization)\n",
    "Model Size: 15-20 MB (EfficientNetB0), < 10 MB (MobileNetV3)\n",
    "```\n",
    "\n",
    "#### **RISK MITIGATION:**\n",
    "- **Haze vs Smoke Confusion**: Use attention mechanisms or ensemble\n",
    "- **Overfitting**: Strong augmentation + dropout + early stopping\n",
    "- **Slow Inference**: Quantization + TensorRT optimization\n",
    "- **Large Model**: MobileNetV3 or pruning\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 NEXT NOTEBOOK\n",
    "Create a training notebook implementing these recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e936548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results for future reference\n",
    "print(\"=\"*60)\n",
    "print(\"EDA COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n📊 Analysis Summary Generated\")\n",
    "print(\"✅ Dataset statistics computed\")\n",
    "print(\"✅ Visualizations created\")\n",
    "print(\"✅ Recommendations provided\")\n",
    "print(\"\\n💡 Review the markdown summary above for actionable insights\")\n",
    "print(\"\\n🚀 Ready to build your CNN model!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
